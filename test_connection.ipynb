{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d5078df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "import pandas as pd\n",
    "\n",
    "project_root = os.path.abspath(\".\")\n",
    "if project_root not in sys.path:\n",
    "    sys.path.append(project_root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6513c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from connectors.database import DatabaseConnector\n",
    "from config.settings import DB_URL\n",
    "\n",
    "connector = DatabaseConnector(DB_URL)\n",
    "engine = connector.connect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b930c3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from load.to_db import DataBaseLoader\n",
    "from load.to_file import FileLoader\n",
    "from extract.from_db import DatabaseExtractor\n",
    "from extract.from_file import FileExtractor\n",
    "from extract.from_API import ExchangeRateFetcher\n",
    "from transform.add_quality import ADDQuality\n",
    "from transform.transformer import DataTransformer\n",
    "from validate.quality_checks import DataValidator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bf09a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:40:53 =>   Extracted 1445 rows from customers.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 7 rows from categories.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 334 rows from products.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 1615 rows from orders.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 10 rows from staffs.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 4764 rows from order_items.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 9 rows from brands.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 3 rows from stores.csv in source\n",
      "2025-04-18 21:40:53 =>   Extracted 939 rows from stocks.csv in source\n",
      "2025-04-18 21:40:54 =>   Fetched 169 exchange rates from openexchangerates\n"
     ]
    }
   ],
   "source": [
    "csv_extractor = FileExtractor(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "source_data_frames = csv_extractor.extract_from_csv(\"source\")\n",
    "exchange_rate_extractor = ExchangeRateFetcher(\"https://openexchangerates.org/api/latest.json?app_id=a92f8bad8e044bc79949a676886da2c8\")\n",
    "exchange_rate_df = exchange_rate_extractor.fetch_exchange_rates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0420705f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:40:54 =>   Loaded 1445 rows into customers.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 7 rows into categories.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 334 rows into products.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 1615 rows into orders in PostgreSQL\n",
      "2025-04-18 21:40:54 =>   Loaded 10 rows into staffs.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 4764 rows into order_items in PostgreSQL\n",
      "2025-04-18 21:40:54 =>   Loaded 9 rows into brands.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 3 rows into stores.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 939 rows into stocks.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Loaded 169 rows into exchange_rates.csv in datalake\n"
     ]
    }
   ],
   "source": [
    "postgres_loader = DataBaseLoader(engine)\n",
    "csv_loader = FileLoader(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "for file_name in source_data_frames.keys():\n",
    "    if file_name == \"orders.csv\" or file_name == \"order_items.csv\":\n",
    "        table_name = file_name.replace(\".csv\", \"\")\n",
    "        postgres_loader.load_to_postgres(source_data_frames[file_name], table_name)\n",
    "    else:\n",
    "        csv_loader.load_to_csv(source_data_frames[file_name], \"datalake\", file_name)\n",
    "csv_loader.load_to_csv(exchange_rate_df, \"datalake\", \"exchange_rates.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c902704",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:40:54 =>   Extracted 1445 rows from customers.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 7 rows from categories.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 334 rows from products.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 169 rows from exchange_rates.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 10 rows from staffs.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 9 rows from brands.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 3 rows from stores.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 939 rows from stocks.csv in datalake\n",
      "2025-04-18 21:40:54 =>   Extracted 4764 rows from PostgreSQL\n",
      "2025-04-18 21:40:54 =>   Extracted 1615 rows from PostgreSQL\n"
     ]
    }
   ],
   "source": [
    "csv_extractor = FileExtractor(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "data_lake_data = csv_extractor.extract_from_csv(\"datalake\")\n",
    "\n",
    "postgres_extractor = DatabaseExtractor(DB_URL)\n",
    "query1 = \"SELECT * FROM order_items\"\n",
    "order_data = postgres_extractor.extract_from_postgres(query1, engine)\n",
    "\n",
    "query2 = \"SELECT * FROM orders\"\n",
    "order_items_data = postgres_extractor.extract_from_postgres(query2, engine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "614dd566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 1445 rows into customers.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 7 rows into categories.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 334 rows into products.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 169 rows into exchange_rates.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 10 rows into staffs.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 9 rows into brands.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 3 rows into stores.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 939 rows into stocks.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 4764 rows into orders.csv in landing\n",
      "2025-04-18 21:40:55 =>    Added source and extraction date to data\n",
      "2025-04-18 21:40:55 =>   Loaded 1615 rows into order_items.csv in landing\n"
     ]
    }
   ],
   "source": [
    "data_quality = ADDQuality()\n",
    "csv_loader = FileLoader(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "for file_name in data_lake_data.keys():\n",
    "    qualified_data = data_quality.add_source_and_date(data_lake_data[file_name], \"data lake\")\n",
    "    csv_loader.load_to_csv(qualified_data, \"landing\", file_name)\n",
    "qualified_data = data_quality.add_source_and_date(order_data, \"postgres db\")\n",
    "csv_loader.load_to_csv(qualified_data, \"landing\", \"orders.csv\")\n",
    "qualified_data = data_quality.add_source_and_date(order_items_data, \"postgres db\")\n",
    "csv_loader.load_to_csv(qualified_data, \"landing\", \"order_items.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad4063fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:40:55 =>   Extracted 1445 rows from customers.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 7 rows from categories.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 334 rows from products.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 4764 rows from orders.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 169 rows from exchange_rates.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 10 rows from staffs.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 1615 rows from order_items.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 9 rows from brands.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 3 rows from stores.csv in landing\n",
      "2025-04-18 21:40:55 =>   Extracted 939 rows from stocks.csv in landing\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:55 =>   Loaded 1445 rows into customers.csv in staging\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:55 =>   Loaded 7 rows into categories.csv in staging\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 13 duplicate rows\n",
      "2025-04-18 21:40:55 =>   Loaded 321 rows into products.csv in staging\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 34 duplicate rows\n",
      "2025-04-18 21:40:55 =>   Loaded 4730 rows into orders.csv in staging\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:55 =>   Loaded 169 rows into exchange_rates.csv in staging\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:55 =>   Loaded 10 rows into staffs.csv in staging\n",
      "2025-04-18 21:40:55 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:55 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:56 =>   Validated data types and handled errors\n",
      "2025-04-18 21:40:56 =>   Loaded 1615 rows into order_items.csv in staging\n",
      "2025-04-18 21:40:56 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:56 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:56 =>   Loaded 9 rows into brands.csv in staging\n",
      "2025-04-18 21:40:56 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:56 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:56 =>   Loaded 3 rows into stores.csv in staging\n",
      "2025-04-18 21:40:56 =>   Handled null values in columns: None with fill value: 0\n",
      "2025-04-18 21:40:56 =>   Removed 0 duplicate rows\n",
      "2025-04-18 21:40:56 =>   Loaded 939 rows into stocks.csv in staging\n"
     ]
    }
   ],
   "source": [
    "csv_extractor = FileExtractor(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "landing_data = csv_extractor.extract_from_csv(\"landing\")\n",
    "for file_name, df in landing_data.items():\n",
    "    data_validator = DataValidator(df)\n",
    "    data_validator.handle_nulls()\n",
    "    data_validator.remove_duplicates()\n",
    "    data_validator.validate_data()\n",
    "    csv_loader.load_to_csv(df, \"staging\", file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2dcf526d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:44:41 =>   Extracted 1445 rows from customers.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 7 rows from categories.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 321 rows from products.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 4730 rows from orders.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 169 rows from exchange_rates.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 10 rows from staffs.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 1615 rows from order_items.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 9 rows from brands.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 3 rows from stores.csv in staging\n",
      "2025-04-18 21:44:41 =>   Extracted 939 rows from stocks.csv in staging\n",
      "2025-04-18 21:44:41 =>   Loaded 1445 rows into customers.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 7 rows into categories.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 321 rows into products.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 4730 rows into orders.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 169 rows into exchange_rates.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 10 rows into staffs.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 1615 rows into order_items.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 9 rows into brands.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 3 rows into stores.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 939 rows into stocks.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 321 rows into products.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 1615 rows into order_items.csv in business\n",
      "2025-04-18 21:44:41 =>   Loaded 1445 rows into customers.csv in business\n"
     ]
    }
   ],
   "source": [
    "csv_extractor = FileExtractor(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "staging_data = csv_extractor.extract_from_csv(\"staging\")\n",
    "for file_name in staging_data.keys():\n",
    "    if file_name != \"products.csv\" or file_name != \"order_items.csv\" or file_name != \"customers.csv\":\n",
    "        csv_loader.load_to_csv(staging_data[file_name], \"business\", file_name)\n",
    "\n",
    "data_transformer = DataTransformer()\n",
    "transformed_products_data = data_transformer.apply_currency_conversion(staging_data[\"products.csv\"], staging_data[\"exchange_rates.csv\"])\n",
    "csv_loader.load_to_csv(transformed_products_data, \"business\", \"products.csv\")\n",
    "transformed_stocks_data = data_transformer.calculate_delivery_metrics(staging_data[\"order_items.csv\"])\n",
    "csv_loader.load_to_csv(transformed_stocks_data, \"business\", \"order_items.csv\")\n",
    "transformed_customers_data = data_transformer.determine_locality_flag(\n",
    "    staging_data['customers.csv'], \n",
    "    staging_data['stores.csv'], \n",
    "    staging_data['order_items.csv']\n",
    ")\n",
    "csv_loader.load_to_csv(transformed_customers_data, \"business\", \"customers.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7032d657",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-04-18 21:56:10 =>   Extracted 1445 rows from customers.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 7 rows from categories.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 321 rows from products.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 4730 rows from orders.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 169 rows from exchange_rates.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 10 rows from staffs.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 1615 rows from order_items.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 9 rows from brands.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 3 rows from stores.csv in business\n",
      "2025-04-18 21:56:10 =>   Extracted 939 rows from stocks.csv in business\n",
      "2025-04-18 21:56:10 =>   Loaded 4730 rows into bigtable.csv in formation_mart\n"
     ]
    }
   ],
   "source": [
    "csv_extractor = FileExtractor(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "business_data = csv_extractor.extract_from_csv(\"business\")\n",
    "\n",
    "merged = pd.merge(business_data['orders.csv'], business_data['order_items.csv'], on='order_id', how='left')\n",
    "merged = pd.merge(merged, business_data['products.csv'], on='product_id', how='left')\n",
    "merged = pd.merge(merged, business_data['brands.csv'], on='brand_id', how='left', \n",
    "                suffixes=('', '_brand'))\n",
    "merged = pd.merge(merged, business_data['customers.csv'], on='customer_id', how='left', \n",
    "                suffixes=('', '_customer'))\n",
    "merged = pd.merge(merged, business_data['stores.csv'], on='store_id', how='left', \n",
    "                suffixes=('', '_store'))\n",
    "merged = pd.merge(merged, business_data['categories.csv'], on='category_id', how='left',\n",
    "                    suffixes=('', '_category'))\n",
    "merged = pd.merge(merged, business_data['staffs.csv'], on='staff_id', how='left', \n",
    "                    suffixes= ('', '_staff'))\n",
    "bigtable = pd.merge(merged, business_data['stocks.csv'], on=['store_id', 'product_id'], \n",
    "                    how='left', suffixes=('', '_stock'))\n",
    "csv_loader = FileLoader(\"/Users/mohamedmoaaz/Desktop/usecase\")\n",
    "csv_loader.load_to_csv(bigtable, \"formation_mart\", \"bigtable.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73eab475",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
